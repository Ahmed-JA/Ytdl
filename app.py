import os, requests, json, threading, time, gc
from flask import Flask, render_template_string, request, jsonify
import yt_dlp
from datetime import timedelta

app = Flask(__name__)

# --- ðŸ”‘ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª ---
def get_engines():
    return {
        "AK-A": {"id": "84031qa6rhfihqe", "secret": "pyoh81kjttomk7b", "ref": "3rGVqjd0T1IAAAAAAAAAAYsivkeMJpEjqt2jPzNFM_Y3ETQBojCGeXadZIMjyFg8"},
        "AK1": {"id": "9d4qz7zbqursfqv", "secret": "m26mrjxgbf8yk91", "ref": "vFHAEY3OTC0AAAAAAAAAAYZ24BsCaJxfipat0zdsJnwy9QTWRRec439kHlYTGYLc"}
    }

RAW_COOKIES = """GPS=1;VISITOR_INFO1_LIVE=20zT46tInss;""" # Ø¶Ø¹ ÙƒÙˆÙƒÙŠØ²Ùƒ Ù‡Ù†Ø§

job_stats = {"active": False, "log": "Ø¬Ø§Ù‡Ø²", "current_file": "-", "total_done": 0, "total_count": 0, "skipped": 0, "start_time": 0, "eta": "00:00:00", "elapsed": "00:00:00"}

def create_cookie_file():
    with open("cookies.txt", "w") as f:
        f.write("# Netscape HTTP Cookie File\n")
        for cookie in RAW_COOKIES.split(';'):
            if '=' in cookie:
                parts = cookie.strip().split('=', 1)
                if len(parts) == 2:
                    f.write(f".youtube.com\tTRUE\t/\tTRUE\t2147483647\t{parts[0]}\t{parts[1]}\n")

def get_token(engine_name):
    e = get_engines().get(engine_name)
    try:
        res = requests.post("https://api.dropboxapi.com/oauth2/token", 
                            data={"grant_type": "refresh_token", "refresh_token": e["ref"], "client_id": e["id"], "client_secret": e["secret"]}, timeout=15)
        return res.json().get("access_token")
    except: return None

def check_exists(token, path):
    headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
    try:
        res = requests.post("https://api.dropboxapi.com/2/files/get_metadata", headers=headers, json={"path": path})
        return res.status_code == 200
    except: return False

def youtube_worker(url, folder_name, mode, quality, sort_by, engine_name):
    global job_stats
    create_cookie_file()
    
    # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ø¯Ø¹Ù… Ø§Ù„Ù‚Ù†ÙˆØ§Øª (Ø¥Ø¶Ø§ÙØ© /videos Ù„Ø¶Ù…Ø§Ù† Ø¬Ù„Ø¨ ÙƒÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª)
    clean_url = url.strip()
    if "/channel/" in clean_url or "/c/" in clean_url or "/@" in clean_url:
        if not clean_url.endswith("/videos"):
            clean_url = clean_url.rstrip('/') + "/videos"

    job_stats.update({"active": True, "log": "ðŸ” Ø¬Ø§Ø±ÙŠ ÙØ­Øµ Ø§Ù„Ù‚Ù†Ø§Ø©/Ø§Ù„Ø±Ø§Ø¨Ø·...", "total_done": 0, "skipped": 0, "start_time": time.time()})
    
    try:
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„Ø¯Ø¹Ù… Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
        ydl_opts = {
            'cookiefile': 'cookies.txt',
            'quiet': True,
            'extract_flat': True, # Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹ Ù„Ø¬Ù„Ø¨ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø³Ø±Ø¹Ø© Ø¯ÙˆÙ† ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª
            'force_generic_extractor': False,
            'ignoreerrors': True
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            res = ydl.extract_info(clean_url, download=False)
            
            if not res:
                raise Exception("ØªØ¹Ø°Ø± Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø±Ø§Ø¨Ø·")

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø³ÙˆØ§Ø¡ ÙƒØ§Ù†Øª Ù‚Ù†Ø§Ø© Ø£Ùˆ Ù‚Ø§Ø¦Ù…Ø© ØªØ´ØºÙŠÙ„ Ø£Ùˆ ÙÙŠØ¯ÙŠÙˆ Ù…ÙØ±Ø¯
            if 'entries' in res:
                videos = [v for v in res['entries'] if v]
            else:
                videos = [res]

            # Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ±ØªÙŠØ¨
            if sort_by == "Most Viewed": videos.sort(key=lambda x: x.get('view_count') or 0, reverse=True)
            elif sort_by == "Newest": videos.sort(key=lambda x: x.get('upload_date') or '', reverse=True)
            elif sort_by == "Oldest": videos.sort(key=lambda x: x.get('upload_date') or '')
            
            job_stats["total_count"] = len(videos)

        for i, video in enumerate(videos):
            token = get_token(engine_name)
            v_url = video.get('url') if video.get('url') else f"https://www.youtube.com/watch?v={video.get('id')}"
            v_title = "".join([c for c in video.get('title', 'Video') if c.isalnum() or c in " "]).strip()
            
            processed = i + 1
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ
            elapsed_sec = time.time() - job_stats["start_time"]
            avg_time = elapsed_sec / processed if processed > 0 else 0
            rem_sec = avg_time * (len(videos) - processed)
            job_stats.update({"elapsed": str(timedelta(seconds=int(elapsed_sec))), "eta": str(timedelta(seconds=int(rem_sec)))})

            tasks = []
            if mode in ["Audio Only", "Both"]: tasks.append(("Audio", "bestaudio/best", "mp3"))
            if mode in ["Videos Only", "Both"]: tasks.append(("Videos", f"best[height<={quality}][ext=mp4]/best", "mp4"))

            for sub, fmt, ext in tasks:
                filename = f"{processed:03d} - {v_title}.{ext}"
                full_path = f"/Ø®Ø§Øµ ÙŠÙˆØªÙŠÙˆØ¨/{folder_name}/{sub}/{filename}"

                if check_exists(token, full_path):
                    job_stats["skipped"] += 1
                    continue

                job_stats.update({"current_file": f"[{sub}] {v_title[:25]}...", "log": f"ðŸ“¡ Ù†Ù‚Ù„ ÙÙŠØ¯ÙŠÙˆ {processed} Ù…Ù† {len(videos)}"})
                
                try:
                    with yt_dlp.YoutubeDL({'format': fmt, 'cookiefile': 'cookies.txt', 'quiet': True, 'noplaylist': True}) as ydl_s:
                        info = ydl_s.extract_info(v_url, download=False)
                        if not info or 'url' not in info: continue
                        
                        with requests.get(info['url'], stream=True, timeout=300) as r:
                            r.raise_for_status()
                            requests.post("https://content.dropboxapi.com/2/files/upload", 
                                         headers={"Authorization": f"Bearer {token}", "Content-Type": "application/octet-stream",
                                                  "Dropbox-API-Arg": json.dumps({"path": full_path, "mode": "overwrite"})}, 
                                         data=r.iter_content(chunk_size=1024*1024))
                except: continue
            
            job_stats["total_done"] = processed
            gc.collect()

        job_stats.update({"log": "âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø¹Ù…Ù„ Ø¨Ù†Ø¬Ø§Ø­", "active": False})
    except Exception as e:
        job_stats.update({"log": f"âš ï¸ Ø®Ø·Ø£: {str(e)[:40]}", "active": False})

# --- (Ø¨Ù‚ÙŠØ© ÙƒÙˆØ¯ Flask ÙˆØ§Ù„Ù€ UI ÙŠØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡Ùˆ Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±) ---
UI = """...""" # Ù†ÙØ³ Ø§Ù„Ù€ UI Ø§Ù„Ø³Ø§Ø¨Ù‚

@app.route('/')
def home(): return render_template_string(UI)

@app.route('/start', methods=['POST'])
def start_job():
    d = request.json
    threading.Thread(target=youtube_worker, args=(d['url'], d['folder'], d['mode'], d['quality'], d['sort'], d['engine'])).start()
    return jsonify({"ok": True})

@app.route('/status')
def get_status(): return jsonify(job_stats)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
